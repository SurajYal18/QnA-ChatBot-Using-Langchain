{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b04819d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in e:\\langchain-project\\.venv\\lib\\site-packages (1.0.7)\n",
      "Requirement already satisfied: langchain-huggingface in e:\\langchain-project\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-community in e:\\langchain-project\\.venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in e:\\langchain-project\\.venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: faiss-cpu in e:\\langchain-project\\.venv\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: pypdf in e:\\langchain-project\\.venv\\lib\\site-packages (6.3.0)\n",
      "Requirement already satisfied: sentence-transformers in e:\\langchain-project\\.venv\\lib\\site-packages (5.1.2)\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-4.15.4-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tiktoken in e:\\langchain-project\\.venv\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.4 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (0.4.43)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\langchain-project\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in e:\\langchain-project\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in e:\\langchain-project\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in e:\\langchain-project\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in e:\\langchain-project\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in e:\\langchain-project\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in e:\\langchain-project\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\langchain-project\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\langchain-project\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\langchain-project\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in e:\\langchain-project\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in e:\\langchain-project\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-huggingface) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: filelock in e:\\langchain-project\\.venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in e:\\langchain-project\\.venv\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in e:\\langchain-project\\.venv\\lib\\site-packages (from langchain-community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\langchain-project\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\langchain-project\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\langchain-project\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\langchain-project\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\langchain-project\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in e:\\langchain-project\\.venv\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in e:\\langchain-project\\.venv\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: Pillow in e:\\langchain-project\\.venv\\lib\\site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\langchain-project\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\langchain-project\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\langchain-project\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in e:\\langchain-project\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in e:\\langchain-project\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in e:\\langchain-project\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\langchain-project\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\langchain-project\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\langchain-project\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading pymongo-4.15.4-cp312-cp312-win_amd64.whl (910 kB)\n",
      "   ---------------------------------------- 0.0/910.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 910.9/910.9 kB 6.9 MB/s  0:00:00\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   ---------------------------------------- 2/2 [pymongo]\n",
      "\n",
      "Successfully installed dnspython-2.8.0 pymongo-4.15.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-huggingface langchain-community langchain-text-splitters faiss-cpu pypdf sentence-transformers pymongo tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49e2f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Langchain-Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import datetime\n",
    "import uuid\n",
    "import shutil\n",
    "from pymongo import MongoClient, errors\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredWordDocumentLoader\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af75c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB:{DB_NAME}\n",
      "Loading Embedding Model\n",
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MONGO_URL=\"mongodb+srv://surajyaligar2004_db_user:LsMU0ZqDZJuyG0Si@documents.pji2q4k.mongodb.net/?appName=Documents\"\n",
    "DB_NAME=\"rag_notebook_db\"\n",
    "COLLECTION_NAME=\"Documents\"\n",
    "\n",
    "VECTOR_STORE_ROOT=\"./vector_stores\"\n",
    "\n",
    "try:\n",
    "    client=MongoClient(MONGO_URL,serverSelectionTimeoutMS=5000)\n",
    "    db=client[DB_NAME]\n",
    "    collection=db[COLLECTION_NAME]\n",
    "\n",
    "    client.server_info()\n",
    "    print(\"Connected to MongoDB:{DB_NAME}\")\n",
    "except errors.ServerSelectionTimeoutError:\n",
    "    print(\"unable to connect mongodb\")\n",
    "\n",
    "if not os.path.exists(VECTOR_STORE_ROOT):\n",
    "    os.makedirs(VECTOR_STORE_ROOT)\n",
    "\n",
    "print(\"Loading Embedding Model\")\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "print(\"Model Loaded\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd197447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Core Functions\n",
    "\n",
    "def count_tokens(text):\n",
    "    try:\n",
    "        if not next:return 0\n",
    "        return len(text)\n",
    "    except Exception:\n",
    "        return 0\n",
    "    \n",
    "def beautify_text(text):\n",
    "    text=re.sub(r'\\s{2,}',' ',text)\n",
    "    text=text.replace('.','\\n.')\n",
    "    return text.strip()\n",
    "\n",
    "def load_file(file_path):\n",
    "    try:\n",
    "        if file_path.lower().endswith('.pdf'):\n",
    "            return PyPDFLoader(file_path).load()\n",
    "        elif file_path.lower().endswith('.txt'):\n",
    "            return TextLoader(file_path,encoding='utf8').load()\n",
    "        elif file_path.lower().endswith('.docx') or file_path.lower().endswith('.doc'):\n",
    "            return UnstructuredWordDocumentLoader(file_path).load()\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def process_and_store_document(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print (f\"Folder path does not exist: {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    files=glob.glob(os.path.join(folder_path,'*.pdf'))+glob.glob(os.path.join(folder_path,'*.txt'))+glob.glob(os.path.join(folder_path,'*.docx'))+glob.glob(os.path.join(folder_path,'*.doc'))\n",
    "    print(f\"Found {len(files)} files.\")\n",
    "\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "\n",
    "    for file_path in files:\n",
    "        filename=os.path.basename(file_path)\n",
    "        if collection.find_one({'filename':filename}):\n",
    "            print(f\"Document {filename} already processed. Skipping.\")\n",
    "            continue\n",
    "        print(f\"Processing file: {filename}\")\n",
    "\n",
    "        try:\n",
    "            docs=load_file(file_path)\n",
    "            if not docs:\n",
    "                continue\n",
    "            \n",
    "            chunks=text_splitter.split_documents(docs)\n",
    "\n",
    "            full_text=\" \".join([d.page_content for d in chunks])\n",
    "            tokens=count_tokens(full_text)\n",
    "\n",
    "            vector_store=FAISS.from_documents(chunks,embeddings)\n",
    "\n",
    "            unique_id=str(uuid.uuid4())\n",
    "            save_path=os.path.join(VECTOR_STORE_ROOT,unique_id)\n",
    "            vector_store.save_local(save_path)\n",
    "            current_time = datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "\n",
    "            record={\n",
    "                \"_id\":unique_id,\n",
    "                \"filename\":filename,\n",
    "                \"file_path\":os.path.abspath(file_path),\n",
    "                \"vector_path\":os.path.abspath(save_path),\n",
    "                \"token_count\":tokens,\n",
    "                \"created_at\":current_time\n",
    "            }\n",
    "            collection.insert_one(record)\n",
    "            print(f\"Successfully processed and stored document: {filename}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "def list_documents():\n",
    "    cursor = collection.find({}, {\"_id\": 1, \"filename\": 1, \"token_count\": 1})\n",
    "    docs = list(cursor)\n",
    "    if not docs:\n",
    "        print(\"ðŸ“­ Database is empty.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\n{'ID':<38} | {'Filename':<20} | {'Tokens'}\")\n",
    "    print(\"-\" * 70)\n",
    "    for d in docs:\n",
    "        print(f\"{d['_id']:<38} | {d['filename'][:20]:<20} | {d.get('token_count',0)}\")\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf543c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 files.\n",
      "Processing file: Basavaraj_YaligarCV.pdf\n",
      "Successfully processed and stored document: Basavaraj_YaligarCV.pdf\n",
      "Document SQL (notes) (1) (1).pdf already processed. Skipping.\n",
      "\n",
      "ID                                     | Filename             | Tokens\n",
      "----------------------------------------------------------------------\n",
      "1f84276c-e749-4ec4-a9c3-cfaf8388bfdc   | SQL (notes) (1) (1). | 10148\n",
      "277e0d54-1767-44a7-95b9-013aa6ac5a39   | Basavaraj_YaligarCV. | 4135\n"
     ]
    }
   ],
   "source": [
    "folder_to_process=\"./my_docs\"\n",
    "\n",
    "if not os.path.exists(folder_to_process):\n",
    "    os.makedirs(folder_to_process)\n",
    "    print(f\"Created folder: {folder_to_process}. Please add documents to process.\")\n",
    "else:\n",
    "    process_and_store_document(folder_to_process)\n",
    "    list_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d444f459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID                                     | Filename             | Tokens\n",
      "----------------------------------------------------------------------\n",
      "1f84276c-e749-4ec4-a9c3-cfaf8388bfdc   | SQL (notes) (1) (1). | 10148\n",
      "277e0d54-1767-44a7-95b9-013aa6ac5a39   | Basavaraj_YaligarCV. | 4135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“– Loaded: Basavaraj_YaligarCV.pdf\n",
      "ðŸ’¬ Chat active. Type 'exit' to stop.\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ’¡ Answers for 'education ':\n",
      "\n",
      "--- Match 1 (Score: 1.5607) ---\n",
      "Date of birth : 02-05-1979\n",
      ". Language known : Kannada, Hindi, English\n",
      ". Strengths : Self confidence, Smart work, team work, Basavaraj U Yaligar\n",
      ".\n",
      "\n",
      "--- Match 2 (Score: 1.7013) ---\n",
      "Diploma in Mechanical Engineering 2011 Indian Institute of Management and Engineering\n",
      ". 72\n",
      ".00% ITI (fitter) 1997 SNVVS ITI Collage Bailhongal 78\n",
      ".00% Training Attended âž¢ Good Manufacturing Practices âž¢ Training on FSSAI requirements\n",
      ". âž¢ Training on FSSC 22000 management system audit âž¢ Training on Advance Manufacturing Food Safety Requirements (FOSTAC)\n",
      ". Total experiences : 25 yrs Marital Status : Married Date of birth : 02-05-1979\n",
      ".\n",
      "\n",
      "--- Match 3 (Score: 1.7247) ---\n",
      "machineries\n",
      ". â€¢ Been a part of team for expansion project of sugar refinery from 3000 to 4000 TPD â€¢ Gained knowledge and experience in maintenance of Carbonation and GAC processes including the Kiln\n",
      ". â€¢ Interacting with O/M management team and identify potential technical issues and providing solutions related to Mechanical Engineering\n",
      ". â€¢ To handle breakdowns in the running plant\n",
      ". â€¢ Implement safety protocols related to maintenance and enhanced\n",
      ".\n",
      "--------------------------------------------------\n",
      "ðŸ‘‹ Chat ended.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "available_docs = list_documents()\n",
    "\n",
    "if available_docs:\n",
    "    target_id = input(\"\\nðŸ‘‰ Copy & Paste the Document ID you want to chat with: \").strip()\n",
    "    \n",
    "    record = collection.find_one({\"_id\": target_id})\n",
    "    \n",
    "    if record:\n",
    "        print(f\"\\nðŸ“– Loaded: {record['filename']}\")\n",
    "        \n",
    "        try:\n",
    "            vector_store = FAISS.load_local(\n",
    "                record['vector_path'], \n",
    "                embeddings, \n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            \n",
    "            print(f\"ðŸ’¬ Chat active. Type 'exit' to stop.\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            while True:\n",
    "                query = input(\"â“ Your Question: \")\n",
    "                if query.lower() in ['exit', 'quit']:\n",
    "                    print(\"ðŸ‘‹ Chat ended.\")\n",
    "                    break\n",
    "                \n",
    "                # Search with Score (Lower score = Better match)\n",
    "                results = vector_store.similarity_search_with_score(query, k=3)\n",
    "                \n",
    "                print(f\"\\nðŸ’¡ Answers for '{query}':\")\n",
    "                for i, (doc, score) in enumerate(results):\n",
    "                    print(f\"\\n--- Match {i+1} (Score: {score:.4f}) ---\")\n",
    "                    print(beautify_text(doc.page_content))\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading vector store: {e}\")\n",
    "    else:\n",
    "        print(\"âŒ Invalid ID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a97ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
